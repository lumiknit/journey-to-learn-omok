{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6xcCa7WMri-"
   },
   "source": [
    "# 03. Monte Carlo like Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hc7ukvCQNFVs"
   },
   "source": [
    "## Naive Deep Learning\n",
    "\n",
    "TicTacToe와 다르게 오목은 상태가 매우 많고\n",
    "행동도 매우 많습니다. 판의 크기를 $9 \\times 9$\n",
    "로만 한정한다고 해도 $3^{81}$ 정도의 경우가 나오지만,\n",
    "이 중 10%를 훑는 것조차 현실적으로 불가능할 정도입니다.\n",
    "이전에 TicTacToe에서 구현한 DNN은 틱택토의 판 상태를\n",
    "통째로 받아서 이를 바탕으로 행동을 결정하는데, 이 경우는\n",
    "적어도 5분 정도 학습을 시켜도 loss가 빠르게 줄어드는\n",
    "시점이 보이며, 알고리즘을 섞어서 exploration을\n",
    "할 경우 알고리즘과 비교적 비슷한 행동을 하도록 만드는 것이\n",
    "가능합니다.\n",
    "\n",
    "하지만 오목의 경우에는 알고리즘만으로 exploration을\n",
    "시도하더라도 loss가 줄어드는 상황을 보기 힘듭니다.\n",
    "아래가 그 구현이며 실제로 매우 안 됩니다.\n",
    "(https://github.com/lumiknit/mock5-q)\n",
    "\n",
    "이 때문에 단순히 오목의 판을 넣고 Q-function의 값을\n",
    "갱신하는 것 외에 더 효율적인 방법을 찾아야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pltHrNHYPOOV"
   },
   "source": [
    "## Decision Tree\n",
    "\n",
    "Decision tree는 각 정점이 상태를 나타내고\n",
    "간선은 해당 상태에서 의사 결정을 통해 분기되는\n",
    "경로를 나타내는 트리입니다.\n",
    "이 상태라는 것이 무엇을 나타내는가는 맥락에 따라 다르지만,\n",
    "게임의 경우에는 보통 현재 판의 상태를 포함하게 됩니다.\n",
    "\n",
    "예를 들자면 체스의 경우에는 살아있는 기물들의 배치가 될\n",
    "것이고, 바둑이나 오목은 돌의 배치가 됩니다.\n",
    "\n",
    "일부 게임의 경우에는 상태만을 저장하게 되면 트리가 아니게\n",
    "될 수 있습니다. 예를 들어서 체스에서 반복된 움직임에\n",
    "의한 스테일메이트 규칙을 제외하면 같은 상태를 무한히\n",
    "반복하는 것이 가능하며, 바둑에서 패를 따내는 것에\n",
    "제한을 없애면 마찬가지로 같은 상태가 무한히 반복될\n",
    "수 있습니다. 이러한 의사결정은 곳 결정 그래프에서\n",
    "사이클을 만들어내는 문제가 있습니다. 다만, 위\n",
    "같은 규칙들이 있거나, 오목처럼 strictly increasing\n",
    "하는 경우에는 크게 고려할 필요가 없습니다.\n",
    "\n",
    "만약에 효율적인 시간 내에 decision tree을 만들어내고\n",
    "그 tree에서 필요한 범위를 탐색할 수 있다면 필승법을\n",
    "찾아낼 수 있습니다.\n",
    "\n",
    "오목의 경우를 예로 들자면 일단 판을 가득채우면 게임이\n",
    "무조건 끝나므로 decision tree는 finite합니다.\n",
    "이 상황에서 inductive하게 판단할 수 있는데,\n",
    "만약 자기보다 낮은 depth의 유불리가 모두\n",
    "판별이 되었다면, 자신의 자식은 모두 상대의 차례이므로,\n",
    "가능한 결정 중 상대에게 가장 불리한 선택지를 고르는 것이\n",
    "자신에게는 유리한 선택입니다.\n",
    "더 나아가, 만약 자기보다 낮은 depth의 모든 노드가\n",
    "'현 상태에서 자신이 둘 차례면 승리하는지 패배하는지'\n",
    "여부가 모두 기록이 되었다면,\n",
    "자신은 자식들 중 패배하는 기록이 하나라도 있다면\n",
    "그 결정을 하여서 상대를 패배시킬 수 있으므로\n",
    "자신은 승리할 수밖에 없으며,\n",
    "반대로 그러한 수가 없으면 자신은 패배하게 됩니다.\n",
    "\n",
    "하지만 이 decision tree의 크기는 가능한 판의 상태의\n",
    "수와 같으므로, 일부를 컴퓨터에 저장하는 것도 힘들 정도로\n",
    "거대합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bMBY4ziTAsZ"
   },
   "source": [
    "## Randomized Algorithm - Monte Carlo Algorithm\n",
    "\n",
    "효율적인 시간 내에 정확한 답을 얻어내는 것은\n",
    "생각보다 많은 문제에서 쉽지 않습니다.\n",
    "이 때문에 결정적이지 않은 알고리즘을 사용해서\n",
    "답을 근사하려고 하는 경우가 종종 있습니다.\n",
    "이런 알고리즘을 probabilistic algorithm\n",
    "(확률적 알고리즘) 또는 \n",
    "randomized algorithm (무작위 알고리즘)\n",
    "이라고 합니다.\n",
    "\n",
    "Randomized algorithm에서 가장 잘 알려져 있는\n",
    "방법은 Monte Carlo method와\n",
    "Las Vegas algorithm입니다.\n",
    "두 알고리즘 모두 무작위로 임의의 값을 뽑은 뒤\n",
    "그 값을 이용하여 원하는 값을 찾아냅니다.\n",
    "이 둘의 차이는 어떤 부분에서\n",
    "무작위인지 아닌지를 나누게 되는데,\n",
    "Monte Carlo는 실행 시간을 특정 시간으로 bound하지만\n",
    "Las Vegas는 정확도에 bound를 하게 됩니다.\n",
    "\n",
    "가장 대표적인 Monte Carlo method의 적용 사례로,\n",
    "원주율을 근사하는 방법이 있겠습니다.\n",
    "원의 넓이는 변의 길이와 원주율의 곱으로 이루어지고\n",
    "임의의 점이 원 내부에 들어가는지 여부는 손쉽게\n",
    "알 수 있기 때문에 가능한 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YqDomC5xTKRj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calc_pi_by_monte_carlo(num_tries):\n",
    "  num_pt_in_circle = 0\n",
    "  for i in range(num_tries):\n",
    "    x = np.random.uniform()\n",
    "    y = np.random.uniform()\n",
    "    if x * x + y * y <= 1.0:\n",
    "      num_pt_in_circle += 1\n",
    "  area = num_pt_in_circle / num_tries # = 0.25 pi\n",
    "  return 4 * area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C_U6GXZHV5sz",
    "outputId": "a8c37658-39a8-40eb-b63a-080a28caae69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/ 10 points = 2.8\n",
      "w/ 100 points = 3.36\n",
      "w/ 10000 points = 3.142\n",
      "w/ 1000000 points = 3.13862\n"
     ]
    }
   ],
   "source": [
    "for i in [10, 100, 10000, 1000000]:\n",
    "  print(\"w/ {} points = {}\".format(i, calc_pi_by_monte_carlo(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hu6lnnyoWAj9"
   },
   "source": [
    "위 결과를 보면 샘플이 많아지면 많아질수록\n",
    "원주율에 근사하는 것을 볼 수 있습니다.\n",
    "이렇듯 Monte Carlo method는 원하는 값이 정확히\n",
    "어떻게 계산되는지 몰라도, 근사를 하는 전략이 되어줍니다.\n",
    "\n",
    "주의할 점은 임의로 샘플링을 하여서 원하는 값으로 수렴한다는\n",
    "것이 증명이 되어야하고, 그 방식에 맞는 확률분포로\n",
    "무작위 값을 뽑아야 한다는 것입니다.\n",
    "위 원주율 계산의 경우 만약 uniform distribution\n",
    "이 아닌 normal distribution을 부여하게 되면\n",
    "일종의 특정 영역에 가중치를 준 것이 되어\n",
    "제대로 계산되지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ohaGX-jHX-c9",
    "outputId": "275fcb10-742b-43e8-c5a8-bb28017cffcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PI from uniform distr = 3.14404\n",
      "PI from normal distr  = 1.57108\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calc_pi_by_monte_carlo_with_normal(num_tries):\n",
    "  num_pt_in_circle = 0\n",
    "  for i in range(num_tries):\n",
    "    x = np.random.normal()\n",
    "    x = max(x, -x)\n",
    "    x = min(x, 1)\n",
    "    y = np.random.normal()\n",
    "    y = max(y, -y)\n",
    "    y = min(y, 1)\n",
    "    if x * x + y * y <= 1.0:\n",
    "      num_pt_in_circle += 1\n",
    "  area = num_pt_in_circle / num_tries # = we wish 0.25 pi\n",
    "  return 4 * area\n",
    "\n",
    "TRIES = 100000\n",
    "pi_with_uniform = calc_pi_by_monte_carlo(TRIES)\n",
    "pi_with_normal = calc_pi_by_monte_carlo_with_normal(TRIES)\n",
    "\n",
    "print(\"PI from uniform distr = {}\".format(pi_with_uniform))\n",
    "print(\"PI from normal distr  = {}\".format(pi_with_normal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ME2DftlAYaRZ"
   },
   "source": [
    "## Monte Carlo Tree Search\n",
    "\n",
    "Monte Carlo Tree Search는\n",
    "decision tree를 정확하게 구하는 대신에\n",
    "Monte Carlo method를 이용하여 무작위 값을 바탕으로\n",
    "근사해나가자는 것입니다.\n",
    "여기서 무작위 값은 임의의 결정이 되며,\n",
    "근사해나가는 것은 해당 상태에서의 승률\n",
    "(정확히는 승패에 관한 통계로, 전체 게임 횟수와\n",
    "그 중 승리한 횟수)입니다.\n",
    "\n",
    "예를 들어서 오목의 경우는 아래와 같이 진행됩니다.\n",
    "\n",
    "0. 각 상태에는 해당 상태를 지나면서 만약 모두 이겼으면 얻을 수 있는 '최대 점수'와 실제 게임 중 얻은 '실제 점수'를 저장.\n",
    "1. 임의의 기보를 생성.\n",
    "2. 기보의 마지막에 승패에 따른 점수를 부여. 예를 들어서 승리할 경우에 1, 무승부거나 패해한 경우에 0\n",
    "3. 해당 점수를 바탕으로 역전파. 우선 '최대 점수'에는 가능한 최대 점수인 1을 더함. Leaf node는 2에서 계산한 점수가 '실제 점수'에 더해지며, parent node에는 child node의 승패여부를 뒤집어서 점수를 계산해서 '실제 점수'에 더하는 것을 반복.\n",
    "\n",
    "즉, 임의의 기보에 대해 이긴 플레이어의 상태에 점수를 더하는 것을 반복하게 됩니다.\n",
    "만약에 이 트리가 충분히 수렴했다면, 자신의 승률이 최대화\n",
    "되는 (= 상대의 승률이 최소화 되는) 선택지가 경험적으로\n",
    "유리한 선택지가 되는 것입니다.\n",
    "\n",
    "다만, 저희는 각 선택에 가중치 없이 골고루 훑어서 가장\n",
    "높은 확률의 선택지를 고르고 싶은 것이다보니, 모든 기보를\n",
    "빠짐없이, 그러면서도 중복되지는 않도록 훑으며 계산을 하는\n",
    "것이 가장 정확합니다.\n",
    "문제는 실제로는 빠짐없이 모든 기보를 훑는 것이\n",
    "너무 오래 걸리고, 각 기보를\n",
    "uniform하게 추출하는 것도 힘든 상황이 많습니다.\n",
    "그래서 적당한 시간에 끊을 수 있으면서도, 주된 상황들을\n",
    "커버할 수 있는 적당한 방법이 필요합니다.\n",
    "\n",
    "이 때문에 실제 Monte Carlo Tree Search는 다음과\n",
    "같이 이루어집니다.\n",
    "\n",
    "1. 현재 존재하는 Tree에 대해 가장 유리한 수를 선택(보통은 특정 정책을 따름)하면서 Leaf까지 내려갑니다.\n",
    "2. 만약 Leaf까지 내려왔는데 게임이 끝나지 않으면 기본 정책을 따라 트리를 탐색합니다.\n",
    "3. 최종적으로 게임이 종료되었다면 역전파를 합니다.\n",
    "4. 이런 방식으로 트리를 충분히 갱신한 뒤에 최적의 수를 선택합니다.\n",
    "\n",
    "여기서 트리를 내려가는 경우에는 단순히 혼자서 게임을\n",
    "진행하면서 학습할 수도 있지만,\n",
    "다른 상대를 두고 번갈아가면서 학습을 할 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dEWUbcZMfnmT"
   },
   "source": [
    "## 다시 TicTacToe\n",
    "\n",
    "TicTacToe는 기보의 수는 많아도 $9! = 362880$개 이하입니다. (9수까지 못 가고 끝날 수 있으므로) \n",
    "특히 첫 수는 회전을 시켜서 상단, 좌상단, 중앙 셋 중\n",
    "하나로 만들 수 있으므로 $3 \\cdot 8! = 120960$\n",
    "으로 경우가 매우 적습니다.\n",
    "그리고 가능한 상태의 수도 많아봐야\n",
    "$222211111_{(3)} + 1 = 19684$개이므로\n",
    "마음만 먹으면 decision tree를 전부 생성하는 것도\n",
    "가능합니다.\n",
    "\n",
    "다만, 여기서는 tree 전체를 생성하는 대신에, 게임을 진행할 수 있는 일부 횟수를 제한하여\n",
    "Monte Carlo Tree Search를 한 뒤에\n",
    "결과를 비교해봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D460oJl6ifu3"
   },
   "source": [
    "### 틱택토 및 알고리즘\n",
    "\n",
    "이전에 사용한 TicTacToe를 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Wp_T1i8Eiq7i"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Game:\n",
    "  def __init__(self):\n",
    "    self.board = [0] * 9\n",
    "    self.turn = 1\n",
    "    self.turns = 0\n",
    "    self.foul = False\n",
    "\n",
    "  def clone(self):\n",
    "    g = Game()\n",
    "    for i in range(9):\n",
    "      g.board[i] = self.board[i]\n",
    "    g.turn = self.turn\n",
    "    g.turns = self.turns\n",
    "    return g\n",
    "\n",
    "  def rotate(self):\n",
    "    # Clone and rotate clockwise\n",
    "    g = Game()\n",
    "    for r in range(3):\n",
    "      for c in range(3):\n",
    "        g.board[3 * r + c] = self.board[3 * (2 - c) + r]\n",
    "    g.turn = self.turn\n",
    "    g.turns = self.turns\n",
    "    return g\n",
    "\n",
    "  def place(self, idx):\n",
    "    # Place stone at board[idx]\n",
    "    # Iff the player cannot place a stone at idx, return False\n",
    "    if self.board[idx] != 0:\n",
    "      self.foul = True\n",
    "      return False\n",
    "    self.board[idx] = self.turn\n",
    "    self.turn = 3 - self.turn\n",
    "    self.turns += 1\n",
    "    return True\n",
    "\n",
    "  def check(self, i0, i1, i2):\n",
    "    # Check whether 3 stones of a same color are placed in i0, i1, i2\n",
    "    v = self.board[i0]\n",
    "    if 0 != v and v == self.board[i1] and v == self.board[i2]:\n",
    "      return v\n",
    "    else: return None\n",
    "\n",
    "  def check_win(self):\n",
    "    # If some player 1 or 2 win, return 1 or 2\n",
    "    # If they draw, return 0\n",
    "    # Otherwise return None\n",
    "    if self.foul:\n",
    "      return 3 - self.turn\n",
    "    r = None\n",
    "    r = r or self.check(0, 1, 2) or self.check(3, 4, 5) or self.check(6, 7, 8)\n",
    "    r = r or self.check(0, 3, 6) or self.check(1, 4, 7) or self.check(2, 5, 8)\n",
    "    r = r or self.check(0, 4, 8) or self.check(2, 4, 6)\n",
    "    if self.turns >= 9: r = r or 0\n",
    "    return r\n",
    "  \n",
    "  def to_numpy(self, player):\n",
    "    # Create 3 * 3 * 3 np array\n",
    "    a = []\n",
    "    for i in range(3):\n",
    "      p = i\n",
    "      if player == 2: p = (3 - p) % 3\n",
    "      b = []\n",
    "      for r in range(3):\n",
    "        col = []\n",
    "        for c in range(3):\n",
    "          col.append(1. if self.board[r * 3 + c] == p else 0.)\n",
    "        b.append(col)\n",
    "      a.append(b)\n",
    "    return np.array(a)\n",
    "\n",
    "  def __str__(self):\n",
    "    ch_arr = ['.', 'O', 'X']\n",
    "    s = \"---\\nTurn: {} ({})\\n\".format(self.turn, ch_arr[self.turn])\n",
    "    s += \" | 0 1 2\\n-+------\"\n",
    "    for r in range(3):\n",
    "      s += \"\\n{}| \".format(r * 3)\n",
    "      for c in range(3):\n",
    "        s += \"{} \".format(ch_arr[self.board[r * 3 + c]])\n",
    "    return s\n",
    "\n",
    "  def play(self, f1, f2, no_print=False):\n",
    "    if no_print: p = lambda x: x\n",
    "    else: p = print\n",
    "    # Play game using two input functions\n",
    "    if f1 == None: f1 = user_input\n",
    "    if f2 == None: f2 = user_input\n",
    "    tfn = [None, f1, f2]\n",
    "    while self.turns < 9: # While empty cell exists\n",
    "      p(str(self))\n",
    "      # Take an index of cell to put a stone\n",
    "      x = tfn[self.turn](self)\n",
    "      p(\"{}P INPUT = {}\".format(self.turn, x))\n",
    "      # Check foul move.\n",
    "      if type(x) != int or x < 0 or x >= 9 or self.board[x] != 0:\n",
    "        p(str(self))\n",
    "        p(\"Player {} put a stone on a non-empty cell!, Player {} win!\" \\\n",
    "            .format(self.turn, 3 - self.turn))\n",
    "        return\n",
    "      # Place a stone\n",
    "      self.place(x)\n",
    "      # Check game is done\n",
    "      w = self.check_win()\n",
    "      if w == 0: # Draw\n",
    "        p(str(self))\n",
    "        p(\"Draw\")\n",
    "        return\n",
    "      elif w != None: # Player `w` win\n",
    "        p(str(self))\n",
    "        p(\"Player {} win!\".format(w))\n",
    "        return\n",
    "    p(str(self))\n",
    "    p(\"Draw\")\n",
    "\n",
    "def user_input(game):\n",
    "  i = None\n",
    "  while i == None:\n",
    "    try:\n",
    "      # Read a index of cell (0~8)\n",
    "      x = input(\"Idx(0~8) > \")\n",
    "      i = int(x)\n",
    "    except:\n",
    "      print(\"Wrong Input!\")\n",
    "  return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9Itc38HhiwKb"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def ttt_alg(game):\n",
    "  # Simple strategy to win TicTacToe\n",
    "  def c(i):\n",
    "    # Check there are 2 same-color stones in a row\n",
    "    v = max([game.board[x] for x in i])\n",
    "    if v == 0: return None\n",
    "    cnt = 0\n",
    "    e = None\n",
    "    for j in range(3):\n",
    "      if v == game.board[i[j]]: cnt += 1\n",
    "      else: e = i[j]\n",
    "    if cnt != 2 or game.board[e] != 0: return None\n",
    "    return e\n",
    "  # The 1st or 2nd stone must be at the center or a corner\n",
    "  if game.turns <= 1:\n",
    "    if game.board[4] == 0: return 4\n",
    "    else: return [0, 2, 6, 8][random.randrange(4)]\n",
    "  # Otherwise, find there are 2 stones in a row\n",
    "  r = c([0, 1, 2]) or c([3, 4, 5]) or c([6, 7, 8])\n",
    "  r = r or c([0, 3, 6]) or c([1, 4, 7]) or c([2, 5, 8])\n",
    "  r = r or c([0, 4, 8]) or c([2, 4, 6])\n",
    "  if r != None: return r\n",
    "  # Otherwise, just pick a random position\n",
    "  for x in [4, 0, 2, 8, 6, 1, 7, 3, 5]:\n",
    "    if game.board[x] == 0: return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EU_T1zxJixlt"
   },
   "source": [
    "여기서\n",
    "각 틱택토 상태를 정수로 인코딩하는 함수를 만들어줍니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hnmXsYkhjJhq"
   },
   "outputs": [],
   "source": [
    "def bd2int(bd):\n",
    "  v = 0\n",
    "  for i in range(9):\n",
    "    v = v * 3 + bd[i]\n",
    "  return v\n",
    "\n",
    "def game2int(game):\n",
    "  return bd2int(game.board)\n",
    "\n",
    "def int2bd(st):\n",
    "  a = [0] * 9\n",
    "  for i in range(9):\n",
    "    a[8 - i] = st % 3\n",
    "    st //= 3\n",
    "  return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hfjPhjyjQ9B",
    "outputId": "848e9990-d037-4056-ae9a-510e684588d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . . . \n",
      "6| . . . \n",
      "81 ---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . O . \n",
      "6| . . . \n",
      "1539 ---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . X \n",
      "3| . O . \n",
      "6| . . . \n",
      "8100 ---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O . X \n",
      "3| . O . \n",
      "6| . . . \n",
      "8597 ---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O . X \n",
      "3| X O . \n",
      "6| O . X \n"
     ]
    }
   ],
   "source": [
    "g = Game()\n",
    "print(game2int(g), g)\n",
    "g.place(4)\n",
    "print(game2int(g), g)\n",
    "g.place(2)\n",
    "print(game2int(g), g)\n",
    "g.place(0)\n",
    "print(game2int(g), g)\n",
    "g.place(8)\n",
    "g.place(6)\n",
    "g.place(3)\n",
    "print(game2int(g), g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DT05jlC3s06f",
    "outputId": "ae12bbfb-aa81-45ef-a48e-c0d268e07fed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 2, 2, 1, 0, 1, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "print(int2bd(8597))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래에서 트리를 생성합니다.\n",
    "트리의 각 노드에는 방문한 횟수와 승리한 횟수를 저장합니다.\n",
    "탐색하는 정책은 단순히 승률이 가장 좋았던 경로를 택합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iD2FR3v6jdXp"
   },
   "outputs": [],
   "source": [
    "class Tree:\n",
    "  def __init__(self):\n",
    "    self.tbl = {}\n",
    "    self.turns = {}\n",
    "    self.children = {}\n",
    "\n",
    "  def find_children(self, st):\n",
    "    if st in self.children: return self.children[st], self.turns[st]\n",
    "    a = int2bd(st)\n",
    "    c = 1\n",
    "    for i in range(9):\n",
    "      if a[i] != 0: c = 3 - c\n",
    "    d = [None] * 9\n",
    "    for i in range(9):\n",
    "      if a[i] == 0:\n",
    "        a[i] = c\n",
    "        d[i] = bd2int(a)\n",
    "        a[i] = 0\n",
    "    self.turns[st] = c\n",
    "    self.children[st] = d\n",
    "    return d, c\n",
    "\n",
    "  def get_win_rate(self, st):\n",
    "    if st in self.tbl:\n",
    "      w, n = self.tbl[st]\n",
    "      return w / n\n",
    "    else:\n",
    "      return 0.5\n",
    "\n",
    "  def update(self, st, inc):\n",
    "    if st in self.tbl:\n",
    "      w, n = self.tbl[st]\n",
    "      self.tbl[st] = (w + inc, n + 1)\n",
    "    else:\n",
    "      self.tbl[st] = (inc, 1)\n",
    "\n",
    "  def backpropagate(self, history, v = None):\n",
    "    if v is None:\n",
    "      v = len(history) % 2\n",
    "    for h in history:\n",
    "      self.update(h, v)\n",
    "      v = 1 - v\n",
    "\n",
    "  def make_decision(self, st):\n",
    "    d, c = self.find_children(st)\n",
    "    maxv = -float('inf')\n",
    "    maxi = -1\n",
    "    for i in range(9):\n",
    "      if d[i] is not None:\n",
    "        v = self.get_win_rate(d[i])\n",
    "        if v > maxv or (v == maxv and np.random.uniform() < 0.5):\n",
    "          maxv = v\n",
    "          maxi = i\n",
    "    return maxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zzip-0T6zKZk"
   },
   "outputs": [],
   "source": [
    "def make_mcts_agent(tree):\n",
    "  def agent(game):\n",
    "    st = game2int(game)\n",
    "    print(list(map(lambda x: tree.get_win_rate(x), tree.find_children(st)[0])))\n",
    "    return tree.make_decision(game2int(game))\n",
    "  return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTvtyJpz6My7"
   },
   "source": [
    "### 자습\n",
    "\n",
    "기본적으로는 자기 자신가 두되,\n",
    "일정 확률로 랜덤한 탐색을 시도합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "uCNzvR6rvNBy"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def independent_learn(num_games):\n",
    "  t = Tree()\n",
    "  for n in range(num_games):\n",
    "    g = Game()\n",
    "    st = game2int(g)\n",
    "    h = [game2int(g)]\n",
    "    winner = None\n",
    "    while winner is None:\n",
    "      if random.random() < 0.3:\n",
    "        i = random.randint(0, 8)\n",
    "        for off in range(9):\n",
    "          j = (off + i) % 9\n",
    "          if g.board[i] == 0:\n",
    "            i = j\n",
    "            break\n",
    "      else:\n",
    "        i = t.make_decision(st)\n",
    "      g.place(i)\n",
    "      st = game2int(g)\n",
    "      h.append(st)\n",
    "      winner = g.check_win()\n",
    "    t.backpropagate(h, 0.5 if winner == 0 else None)\n",
    "    if n % 50000 == 50000 - 1:\n",
    "      print(\"{:7.3f}% Done\".format(100.0 * ((n + 1) / num_games)))\n",
    "  return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k7UannOUzH_z",
    "outputId": "4d59d2dc-8191-4876-d6fa-063302ba40cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covered # of states: 2393\n"
     ]
    }
   ],
   "source": [
    "t = independent_learn(3000)\n",
    "print(\"Covered # of states: {}\".format(len(t.tbl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lX0p0jyazoyS",
    "outputId": "e708a321-bc4f-4999-b65c-4f773338a764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . . . \n",
      "6| . . . \n",
      "1P INPUT = 4\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . O . \n",
      "6| . . . \n",
      "[0.4062273714699493, 0.24305555555555555, 0.26344086021505375, 0.3302752293577982, 0.5, 0.31333333333333335, 0.38461538461538464, 0.28125, 0.3531468531468531]\n",
      "2P INPUT = 0\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| X . . \n",
      "3| . O . \n",
      "6| . . . \n",
      "1P INPUT = 2\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| X . O \n",
      "3| . O . \n",
      "6| . . . \n",
      "[0.5, 0.0, 0.5, 0.25, 0.5, 0.5, 0.6222222222222222, 0.25, 0.2]\n",
      "2P INPUT = 6\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| X . O \n",
      "3| . O . \n",
      "6| X . . \n",
      "1P INPUT = 3\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| X . O \n",
      "3| O O . \n",
      "6| X . . \n",
      "[0.5, 0.3333333333333333, 0.5, 0.5, 0.5, 0.4666666666666667, 0.5, 0.25, 0.0]\n",
      "2P INPUT = 5\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| X . O \n",
      "3| O O X \n",
      "6| X . . \n",
      "1P INPUT = 8\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| X . O \n",
      "3| O O X \n",
      "6| X . O \n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "2P INPUT = 7\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| X . O \n",
      "3| O O X \n",
      "6| X X O \n",
      "1P INPUT = 1\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| X O O \n",
      "3| O O X \n",
      "6| X X O \n",
      "Draw\n"
     ]
    }
   ],
   "source": [
    "Game().play(ttt_alg, make_mcts_agent(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZ_C3zCE6khi",
    "outputId": "ac835133-4d51-4ea6-e0cd-a605a0874ec9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . . . \n",
      "6| . . . \n",
      "[0.5868055555555556, 0.5431034482758621, 0.5614035087719298, 0.5669291338582677, 0.6566265060240963, 0.5672268907563025, 0.5618556701030928, 0.610236220472441, 0.5702702702702702]\n",
      "1P INPUT = 4\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . O . \n",
      "6| . . . \n",
      "2P INPUT = 2\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . X \n",
      "3| . O . \n",
      "6| . . . \n",
      "[0.8333333333333334, 0.375, 0.5, 0.3333333333333333, 0.5, 0.823076923076923, 0.5, 0.6923076923076923, 0.6428571428571429]\n",
      "1P INPUT = 0\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O . X \n",
      "3| . O . \n",
      "6| . . . \n",
      "2P INPUT = 8\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O . X \n",
      "3| . O . \n",
      "6| . . X \n",
      "[0.5, 0.2, 0.5, 0.6666666666666666, 0.5, 0.5, 0.4, 0.0, 0.5]\n",
      "1P INPUT = 3\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O . X \n",
      "3| O O . \n",
      "6| . . X \n",
      "2P INPUT = 5\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O . X \n",
      "3| O O X \n",
      "6| . . X \n",
      "Player 2 win!\n"
     ]
    }
   ],
   "source": [
    "Game().play(make_mcts_agent(t), ttt_alg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLcGQWyXIw9J"
   },
   "source": [
    "약 3000판의 플레이를 하게 되면 2500개 정도의 기보를 커버하게 되며, 대략 이 쯤부터 알고리즘과 무승부를 낼 수 있게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mzzchRF964qK",
    "outputId": "1328835d-4ded-421f-e491-e8144dd3883c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.000% Done\n",
      " 10.000% Done\n",
      " 15.000% Done\n",
      " 20.000% Done\n",
      " 25.000% Done\n",
      " 30.000% Done\n",
      " 35.000% Done\n",
      " 40.000% Done\n",
      " 45.000% Done\n",
      " 50.000% Done\n",
      " 55.000% Done\n",
      " 60.000% Done\n",
      " 65.000% Done\n",
      " 70.000% Done\n",
      " 75.000% Done\n",
      " 80.000% Done\n",
      " 85.000% Done\n",
      " 90.000% Done\n",
      " 95.000% Done\n",
      "100.000% Done\n",
      "Covered # of states: 5377\n"
     ]
    }
   ],
   "source": [
    "t = independent_learn(1000000)\n",
    "print(\"Covered # of states: {}\".format(len(t.tbl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RqDJ9_lt69k2",
    "outputId": "a82d9ebb-f2c2-4cc3-ea0a-a342ede08eb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . . . \n",
      "6| . . . \n",
      "1P INPUT = 4\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . O . \n",
      "6| . . . \n",
      "[0.4331034741221002, 0.301353226925746, 0.43375141888223806, 0.295502716867702, 0.5, 0.29867516987434994, 0.42793088786672334, 0.30084992432180696, 0.4321864224537466]\n",
      "2P INPUT = 2\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . X \n",
      "3| . O . \n",
      "6| . . . \n",
      "1P INPUT = 0\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O . X \n",
      "3| . O . \n",
      "6| . . . \n",
      "[0.5, 0.15832205683355885, 0.5, 0.17529107373868047, 0.5, 0.23716012084592145, 0.13215859030837004, 0.16330935251798562, 0.5305025882969662]\n",
      "2P INPUT = 8\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O . X \n",
      "3| . O . \n",
      "6| . . X \n",
      "1P INPUT = 5\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O . X \n",
      "3| . O O \n",
      "6| . . X \n",
      "[0.5, 0.18693693693693694, 0.5, 0.5019640779788516, 0.5, 0.5, 0.20967741935483872, 0.21049046321525886, 0.5]\n",
      "2P INPUT = 3\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O . X \n",
      "3| X O O \n",
      "6| . . X \n",
      "1P INPUT = 6\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O . X \n",
      "3| X O O \n",
      "6| O . X \n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "2P INPUT = 7\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O . X \n",
      "3| X O O \n",
      "6| O X X \n",
      "1P INPUT = 1\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O O X \n",
      "3| X O O \n",
      "6| O X X \n",
      "Draw\n"
     ]
    }
   ],
   "source": [
    "Game().play(ttt_alg, make_mcts_agent(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAHql4876-Or",
    "outputId": "b7dd41fc-3888-47f4-adf0-c073af760972"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . . . \n",
      "6| . . . \n",
      "[0.5869054295863045, 0.5588778742374472, 0.5840691420518278, 0.5594824865888293, 0.6162251123209542, 0.5616656162264367, 0.5837541256452933, 0.5630093047448419, 0.5849279538904899]\n",
      "1P INPUT = 4\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . O . \n",
      "6| . . . \n",
      "2P INPUT = 8\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . O . \n",
      "6| . . X \n",
      "[0.549, 0.5850642927794263, 0.5909090909090909, 0.572208228379513, 0.5, 0.6236459921367247, 0.6060498220640569, 0.6252547801611181, 0.5]\n",
      "1P INPUT = 7\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . O . \n",
      "6| . O X \n",
      "2P INPUT = 1\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . X . \n",
      "3| . O . \n",
      "6| . O X \n",
      "[0.5359195402298851, 0.5, 0.6077616077616078, 0.6009253903990746, 0.5, 0.5786219081272085, 0.3376383763837638, 0.5, 0.5]\n",
      "1P INPUT = 2\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . X O \n",
      "3| . O . \n",
      "6| . O X \n",
      "2P INPUT = 6\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . X O \n",
      "3| . O . \n",
      "6| X O X \n",
      "[0.5810356422326832, 0.5, 0.5, 0.5972549019607843, 0.5, 0.5927152317880795, 0.5, 0.5, 0.5]\n",
      "1P INPUT = 3\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . X O \n",
      "3| O O . \n",
      "6| X O X \n",
      "2P INPUT = 5\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . X O \n",
      "3| O O X \n",
      "6| X O X \n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "1P INPUT = 0\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O X O \n",
      "3| O O X \n",
      "6| X O X \n",
      "Draw\n"
     ]
    }
   ],
   "source": [
    "Game().play(make_mcts_agent(t), ttt_alg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q53N2kli7h8Q"
   },
   "source": [
    "게임 횟수를 약 5배로 늘려보아도 커버하는 경우가 확연히 늘어나지는 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTzHjUW89H5F"
   },
   "source": [
    "### 힌트 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "39Cm9hLB9PGi"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def hint_learn(num_games):\n",
    "  t = Tree()\n",
    "  epsilon = 0.8\n",
    "  ep_dec = 0.99\n",
    "  for n in range(num_games):\n",
    "    g = Game()\n",
    "    st = game2int(g)\n",
    "    h = [game2int(g)]\n",
    "    winner = None\n",
    "    epsilon *= ep_dec\n",
    "    while winner is None:\n",
    "      if random.random() < epsilon:\n",
    "        i = ttt_alg(g)\n",
    "      else:\n",
    "        i = t.make_decision(st)\n",
    "      g.place(i)\n",
    "      st = game2int(g)\n",
    "      h.append(st)\n",
    "      winner = g.check_win()\n",
    "    t.backpropagate(h, 0.5 if winner == 0 else None)\n",
    "    if n % 50000 == 50000 - 1:\n",
    "      print(\"{:7.3f}% Done\".format(100.0 * ((n + 1) / num_games)))\n",
    "  return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WngYRz2G9Xjr",
    "outputId": "8da9675e-a89f-4e90-b0da-94261f097111"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covered # of states: 269\n",
      "<__main__.Tree object at 0x7f0e5da902d0>\n"
     ]
    }
   ],
   "source": [
    "t = hint_learn(200)\n",
    "print(\"Covered # of states: {}\".format(len(t.tbl)))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybTz-kCQ9lDc",
    "outputId": "f559e51a-7704-49a6-dfc5-7c7450c8dcc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . . . \n",
      "6| . . . \n",
      "1P INPUT = 4\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . O . \n",
      "6| . . . \n",
      "[0.4609375, 0.0, 0.3611111111111111, 0.0, 0.5, 0.3, 0.3333333333333333, 0.25, 0.3125]\n",
      "2P INPUT = 0\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| X . . \n",
      "3| . O . \n",
      "6| . . . \n",
      "1P INPUT = 2\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| X . O \n",
      "3| . O . \n",
      "6| . . . \n",
      "[0.5, 0.0, 0.5, 0.3333333333333333, 0.5, 0.5, 0.5, 0.0, 0.0]\n",
      "2P INPUT = 6\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| X . O \n",
      "3| . O . \n",
      "6| X . . \n",
      "1P INPUT = 3\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| X . O \n",
      "3| O O . \n",
      "6| X . . \n",
      "[0.5, 0.0, 0.5, 0.5, 0.5, 0.4666666666666667, 0.5, 0.25, 0.0]\n",
      "2P INPUT = 5\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| X . O \n",
      "3| O O X \n",
      "6| X . . \n",
      "1P INPUT = 8\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| X . O \n",
      "3| O O X \n",
      "6| X . O \n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "2P INPUT = 1\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| X X O \n",
      "3| O O X \n",
      "6| X . O \n",
      "1P INPUT = 7\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| X X O \n",
      "3| O O X \n",
      "6| X O O \n",
      "Draw\n"
     ]
    }
   ],
   "source": [
    "Game().play(ttt_alg, make_mcts_agent(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8UiPeDvsJh-k",
    "outputId": "cd9e8e8e-eb40-4398-ce6a-26007d04e92b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . . . \n",
      "6| . . . \n",
      "[0.5, 0.5, 0.5, 0.5, 0.59, 0.5, 0.5, 0.5, 0.5]\n",
      "1P INPUT = 4\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . O . \n",
      "6| . . . \n",
      "2P INPUT = 6\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . O . \n",
      "6| X . . \n",
      "[0.6666666666666666, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "1P INPUT = 0\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O . . \n",
      "3| . O . \n",
      "6| X . . \n",
      "2P INPUT = 8\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O . . \n",
      "3| . O . \n",
      "6| X . X \n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.59375, 0.5]\n",
      "1P INPUT = 7\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O . . \n",
      "3| . O . \n",
      "6| X O X \n",
      "2P INPUT = 1\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O X . \n",
      "3| . O . \n",
      "6| X O X \n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "1P INPUT = 3\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O X . \n",
      "3| O O . \n",
      "6| X O X \n",
      "2P INPUT = 5\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O X . \n",
      "3| O O X \n",
      "6| X O X \n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "1P INPUT = 2\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O X O \n",
      "3| O O X \n",
      "6| X O X \n",
      "Draw\n"
     ]
    }
   ],
   "source": [
    "Game().play(make_mcts_agent(t), ttt_alg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuF2KIZfBrZr"
   },
   "source": [
    "algorithm 자체를 힌트로 주고 기보를\n",
    "누적할 경우에는 훨씬 적은 횟수로도\n",
    "'알고리즘이 두는 방식'으로 학습을 시키는 것이 가능합니다.\n",
    "(다만, 이 경우는 커버리지 자체가 넓지 않기 때문에\n",
    "알고리즘과 다른 스타일로 두게 되면 매우 약해질 수 있습니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yZ1VxLhKYfc"
   },
   "source": [
    "## Beat the algorithm down\n",
    "\n",
    "이번 파트를 마무리하기 전,\n",
    "지금까지 사용한 틱택토 알고리즘을\n",
    "무승부가 아니라 이기는 것은 불가능한지\n",
    "확인하고 넘어가고자 합니다.\n",
    "\n",
    "이를 위해서 모든 경우를 순회해도 되겠지만,\n",
    "MCTS로 얼마나 반복하면 이 경우까지 커버가\n",
    "되는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "nT0cwXDRM7o-"
   },
   "outputs": [],
   "source": [
    "class Tree:\n",
    "  def __init__(self):\n",
    "    self.tbl = {}\n",
    "    self.turns = {}\n",
    "    self.children = {}\n",
    "\n",
    "  def find_children(self, st):\n",
    "    if st in self.children: return self.children[st], self.turns[st]\n",
    "    a = int2bd(st)\n",
    "    c = 1\n",
    "    for i in range(9):\n",
    "      if a[i] != 0: c = 3 - c\n",
    "    d = [None] * 9\n",
    "    for i in range(9):\n",
    "      if a[i] == 0:\n",
    "        a[i] = c\n",
    "        d[i] = bd2int(a)\n",
    "        a[i] = 0\n",
    "    self.turns[st] = c\n",
    "    self.children[st] = d\n",
    "    return d, c\n",
    "\n",
    "  def get_win_rate(self, st):\n",
    "    if st in self.tbl:\n",
    "      w, n = self.tbl[st]\n",
    "      return w / n\n",
    "    else:\n",
    "      return 0.5\n",
    "\n",
    "  def update(self, st, inc):\n",
    "    if st in self.tbl:\n",
    "      w, n = self.tbl[st]\n",
    "      self.tbl[st] = (w + inc, n + 1)\n",
    "    else:\n",
    "      self.tbl[st] = (inc, 1)\n",
    "\n",
    "  def backpropagate(self, history, w = 1.0):\n",
    "    v = len(history) % 2\n",
    "    for h in history:\n",
    "      self.update(h, v * w)\n",
    "      v = 1 - v\n",
    "\n",
    "  def make_decision(self, st):\n",
    "    d, c = self.find_children(st)\n",
    "    maxv = -float('inf')\n",
    "    maxi = -1\n",
    "    for i in range(9):\n",
    "      if d[i] is not None:\n",
    "        v = self.get_win_rate(d[i])\n",
    "        if v > maxv or (v == maxv and np.random.uniform() < 0.5):\n",
    "          maxv = v\n",
    "          maxi = i\n",
    "    return maxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "gTxIbgBNK4kd"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def ext_learn(num_games):\n",
    "  t = Tree()\n",
    "  epsilon = 1.0\n",
    "  ep_dec = 0.9999\n",
    "  min_ep = 0.3\n",
    "  for n in range(num_games):\n",
    "    epsilon *= ep_dec\n",
    "    if epsilon < min_ep: epsilon = min_ep\n",
    "    g = Game()\n",
    "    st = game2int(g)\n",
    "    h = [game2int(g)]\n",
    "    winner = None\n",
    "    while winner is None:\n",
    "      if random.random() < epsilon:\n",
    "        a = []\n",
    "        for j in range(9):\n",
    "          if g.board[j] == 0:\n",
    "            a.append(j)\n",
    "        i = a[random.randint(0, len(a) - 1)]\n",
    "      elif random.random() < 0.1:\n",
    "        i = ttt_alg(g)\n",
    "      else:\n",
    "        i = t.make_decision(st)\n",
    "      g.place(i)\n",
    "      st = game2int(g)\n",
    "      h.append(st)\n",
    "      winner = g.check_win()\n",
    "    t.backpropagate(h, 0.0 if winner == 0 else 1.0)\n",
    "    if n % 1000 == 1000 - 1:\n",
    "      print(\"{:7.3f}% Done (#St = {})\".format(100.0 * ((n + 1) / num_games), len(t.tbl)))\n",
    "  return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P_FpqP7-K_jo",
    "outputId": "1f594ea1-b77b-49a5-c51a-054dabdb1d57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10.000% Done (#St = 3166)\n",
      " 20.000% Done (#St = 4297)\n",
      " 30.000% Done (#St = 4837)\n",
      " 40.000% Done (#St = 5095)\n",
      " 50.000% Done (#St = 5206)\n",
      " 60.000% Done (#St = 5272)\n",
      " 70.000% Done (#St = 5308)\n",
      " 80.000% Done (#St = 5329)\n",
      " 90.000% Done (#St = 5342)\n",
      "100.000% Done (#St = 5349)\n",
      "Covered # of states: 5349\n"
     ]
    }
   ],
   "source": [
    "t = ext_learn(10000)\n",
    "print(\"Covered # of states: {}\".format(len(t.tbl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-mYduTOLCv3",
    "outputId": "71866d0f-44ba-4a69-844b-72c3d7660a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . . . \n",
      "6| . . . \n",
      "[0.5818673883626523, 0.6055312954876274, 0.6048850574712644, 0.5140845070422535, 0.7235715938006014, 0.5494186046511628, 0.5964432284541724, 0.550326797385621, 0.6006051437216339]\n",
      "1P INPUT = 4\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . O . \n",
      "6| . . . \n",
      "2P INPUT = 8\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . O . \n",
      "6| . . X \n",
      "[0.625, 0.639344262295082, 0.6585365853658537, 0.7209302325581395, 0.5, 0.7555555555555555, 0.7105263157894737, 0.8192090395480226, 0.5]\n",
      "1P INPUT = 7\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . O . \n",
      "6| . O X \n",
      "2P INPUT = 1\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . X . \n",
      "3| . O . \n",
      "6| . O X \n",
      "[0.5, 0.5, 0.5, 0.6363636363636364, 0.5, 0.7, 0.3333333333333333, 0.5, 0.5]\n",
      "1P INPUT = 5\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . X . \n",
      "3| . O O \n",
      "6| . O X \n",
      "2P INPUT = 3\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . X . \n",
      "3| X O O \n",
      "6| . O X \n",
      "[0.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5714285714285714, 0.5, 0.5]\n",
      "1P INPUT = 6\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . X . \n",
      "3| X O O \n",
      "6| O O X \n",
      "2P INPUT = 2\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . X X \n",
      "3| X O O \n",
      "6| O O X \n",
      "[0.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "1P INPUT = 0\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O X X \n",
      "3| X O O \n",
      "6| O O X \n",
      "Draw\n"
     ]
    }
   ],
   "source": [
    "Game().play(make_mcts_agent(t), ttt_alg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kJcaIybLD7c",
    "outputId": "d8419f3a-11e9-4eb1-ca62-7060e50779a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . . . \n",
      "6| . . . \n",
      "1P INPUT = 4\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . . \n",
      "3| . O . \n",
      "6| . . . \n",
      "[0.22448979591836735, 0.18269230769230768, 0.22718052738336714, 0.16447368421052633, 0.5, 0.14792899408284024, 0.22493887530562348, 0.19572953736654805, 0.1837837837837838]\n",
      "2P INPUT = 2\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| . . X \n",
      "3| . O . \n",
      "6| . . . \n",
      "1P INPUT = 0\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O . X \n",
      "3| . O . \n",
      "6| . . . \n",
      "[0.5, 0.058823529411764705, 0.5, 0.05263157894736842, 0.5, 0.3333333333333333, 0.09090909090909091, 0.0, 0.373134328358209]\n",
      "2P INPUT = 8\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O . X \n",
      "3| . O . \n",
      "6| . . X \n",
      "1P INPUT = 5\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O . X \n",
      "3| . O O \n",
      "6| . . X \n",
      "[0.5, 0.0, 0.5, 0.0, 0.5, 0.5, 0.08, 0.13333333333333333, 0.5]\n",
      "2P INPUT = 7\n",
      "---\n",
      "Turn: 1 (O)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O . X \n",
      "3| . O O \n",
      "6| . X X \n",
      "1P INPUT = 3\n",
      "---\n",
      "Turn: 2 (X)\n",
      " | 0 1 2\n",
      "-+------\n",
      "0| O . X \n",
      "3| O O O \n",
      "6| . X X \n",
      "Player 1 win!\n"
     ]
    }
   ],
   "source": [
    "Game().play(ttt_alg, make_mcts_agent(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAgdF5tILEOi"
   },
   "source": [
    "위에서는 일부 학습 정책을 바꿔서 탐색하는 속도를 수정하였습니다.\n",
    "원래 TicTacToe는 양측이 수를 완벽하게 읽으면 항상\n",
    "무승부가 나올 수밖에 없는데, 여기서는 이기기 위한\n",
    "수들만을 남기기 위해서 무승부에 대해 양측에\n",
    "어떠한 점수도 주지 않았습니다.\n",
    "아직 탐색을 하지 않았다면\n",
    "최소한 0.5라는 점수는 주기 때문에, 이 경우\n",
    "이미 진다고 확인한 곳보다는 방문하지 않은 정점을\n",
    "먼저 탐색을 하게 됩니다.\n",
    "추가적으로 랜덤 탐색을 할 때에도 남은 칸에 대해서\n",
    "uniform한 확률로 선택이 되도록 수정을 하였습니다.\n",
    "\n",
    "위와 같이 학습을 하였을 때 약 5000번 동안\n",
    "5000개 가량의 상태를 커버하였고, 이후부터는 조금씩\n",
    "방문하지 않은 일부 상태만을 확인할 뿐\n",
    "급격한 변화는 없습니다.\n",
    "\n",
    "아래에서 MCTS가 후공인 경우에 알고리즘을 이기는 것을\n",
    "확인할 수 있는데, 이 부분에서 알고리즘이 고려하지 않은\n",
    "경우 또는 버그가 있다는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhVdy6awRSzs"
   },
   "source": [
    "참고로 틱택토의 모든 경우의 수는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PRFYZKZURV88",
    "outputId": "099ca602-aa58-414a-b776-bd6747861452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5478\n"
     ]
    }
   ],
   "source": [
    "def gen_full_tree(t, st):\n",
    "  if st not in t.children:\n",
    "    d, z = t.find_children(st)\n",
    "    g = Game()\n",
    "    g.board = int2bd(st)\n",
    "    if g.check_win() is None:\n",
    "      for i in d:\n",
    "        if i is not None:\n",
    "          gen_full_tree(t, i)\n",
    "  return t\n",
    "print(len(gen_full_tree(Tree(), 0).children))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "03_monte_carlo_tree_search.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
